name: Download files from SUS FTP
run-name: ${{ github.actor }} is collecting data using GitHub Actions üöÄ
on: 
  workflow_dispatch:
    inputs:
      states:
        description: 'States to collect files'
        required: false
        default: 'RO,AC,AM,RR,PA,AP,TO,MA,PI,CE,RN,PB,PE,AL,SE,BA,MG,ES,RJ,SP,PR,SC,RS,MS,MT,GO,DF'
      start_date:
        description: 'Start date (YYYY-MM-DD)'
        required: false
      end_date:
        description: 'End date (YYYY-MM-DD)'
        required: false
    # agendamento para execucao todo dia as 8:00 da manh√£
  schedule:
    - cron:  '0 8 * * *'
jobs:
  Collecting-Data-Using-GitHub-Actions:
    runs-on: ubuntu-latest
    steps:
      - run: echo "üéâ The job was automatically triggered by a ${{ github.event_name }} event."
      - run: echo "üêß This job is now running on a ${{ runner.os }} server hosted by GitHub!"
      - run: echo "üîé The name of your branch is ${{ github.ref }} and your repository is ${{ github.repository }}."
      - name: Check out repository code
        uses: actions/checkout@v3
      - run: echo "üí° The ${{ github.repository }} repository has been cloned to the runner."
      - run: echo "üñ•Ô∏è The workflow is now ready to test your code on the runner."
      - name: List files in the repository
        run: |
          ls ${{ github.workspace }}
      - name: 'google-auth'
        uses: 'google-github-actions/auth@v1'
        with:
          credentials_json: '${{ secrets.gcp_credentials }}'
      - name: Create output and temp dir
        run: |  
          export OUTPUT_DIR=${{ github.workspace }}/output-files
          export TEMP_DIR=${{ github.workspace }}/temp-files          
          mkdir ${OUTPUT_DIR}
          mkdir ${TEMP_DIR}
          mkdir ${TEMP_DIR}/dbc-files
          chmod o+w  ${TEMP_DIR}/dbc-files/.
          mkdir ${TEMP_DIR}/dbf-files
          chmod o+w ${TEMP_DIR}/dbf-files/.
          mkdir ${TEMP_DIR}/csv-files
          chmod o+w ${TEMP_DIR}/csv-files/.          

      - name: 'install gcsfuse to access bucket'
        run: |
          export GCSFUSE_REPO=gcsfuse-`lsb_release -c -s`
          echo "deb https://packages.cloud.google.com/apt $GCSFUSE_REPO main" | sudo tee /etc/apt/sources.list.d/gcsfuse.list
          curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
          sudo apt-get update
          sudo apt-get install gcsfuse

          sudo groupadd fuse
          sudo usermod -a -G fuse $USER
          sudo chown $USER_ID:fuse ${{ github.workspace }}/output-files
          
          gcsfuse --dir-mode=777 --file-mode=777 --key-file=$GOOGLE_APPLICATION_CREDENTIALS --implicit-dirs observatorio-oncologia ${{ github.workspace }}/output-files
          # gcsfuse  --implicit-dirs observatorio-oncologia ${{ github.workspace }}/output-files          
          
      - name: Prepare permissions, scripts and call script to collect files
        working-directory: ./auto-get-files
        run: |
          chmod +x collect_from_ftp.sh
          cd ./blast
          gcc blast.c blast-dbf.c -o ../dbc-2-dbf
          cd ..
          chmod +x dbc-2-dbf
          export OUTPUT_DIR=${{ github.workspace }}/output-files/monitor
          export TEMP_DIR=${{ github.workspace }}/temp-files          
          export DBC_DIR=${TEMP_DIR}/dbc-files
          export DBF_DIR=${TEMP_DIR}/dbf-files
          export CSV_DIR=${TEMP_DIR}/csv-files  
          
          pip3 install -r ../requirements.txt
          export STATES=${{ github.event.inputs.states}}
          export START_DATE=${{ github.event.inputs.start_date}}
          export END_DATE=${{ github.event.inputs.end_date}}          
          python3 ./main.py

      - run: echo "üçè This job's status is ${{ job.status }}."
      - uses: gautamkrishnar/keepalive-workflow@v1 # using the workflow with default settings
